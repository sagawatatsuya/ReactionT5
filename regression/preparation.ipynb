{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd190b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, T5EncoderModel, get_linear_schedule_with_warmup\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "import sentencepiece\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "disable_progress_bar()\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_path\", type=str, required=False)\n",
    "#     parser.add_argument(\"--dataset_name\", type=str, required=False)\n",
    "    parser.add_argument(\"--pretrained_model_name_or_path\", type=str, default=\"sagawa/ZINC-t5\", required=False)\n",
    "    parser.add_argument(\"--model_name_or_path\", type=str, required=False)\n",
    "    parser.add_argument(\"--scaler_path\", type=str, default=\"/data2/sagawa/tcrp-regression-model-archive/10-23-1st-new-metric-reactant-product\", required=False)\n",
    "    parser.add_argument(\"--debug\", action='store_true', default=False, required=False)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=5, required=False)\n",
    "    parser.add_argument(\"--max_len\", type=int, default=512, required=False)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=1, required=False)\n",
    "    parser.add_argument(\"--fc_dropout\", type=float, default=0.1, required=False)\n",
    "    parser.add_argument(\"--output_dir\", type=str, default='./', required=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, required=False)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "class CFG():\n",
    "    data_path='../../all_ord_reaction_uniq_with_attr_v3.tsv'\n",
    "#     pretrained_model_name_or_path = 'sagawa/ZINC-t5'\n",
    "    model = 'sagawa/ZINC-t5'\n",
    "    batch_size = 5 #max_lenを大きくしたらoomしたから15から5に\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    output_dir = './'\n",
    "    model_name_or_path = '/data2/sagawa/tcrp-regression-model-archive/10-23-1st-new-metric-reactant-product'\n",
    "    scaler_path = '/data2/sagawa/tcrp-regression-model-archive/10-23-1st-new-metric-reactant-product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b7bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATALYST</th>\n",
       "      <th>REACTANT</th>\n",
       "      <th>REAGENT</th>\n",
       "      <th>SOLVENT</th>\n",
       "      <th>INTERNAL_STANDARD</th>\n",
       "      <th>NoData</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>YIELD</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2ccccc2C12CCCC2</td>\n",
       "      <td></td>\n",
       "      <td>ClCCl</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CC#CN1C(=O)C(C)Oc2ccc(-n3c(=O)cc(C(F)(F)F)[nH]...</td>\n",
       "      <td>98.0</td>\n",
       "      <td></td>\n",
       "      <td>REACTANT:CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2cccc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Pd]</td>\n",
       "      <td>CC(C)(C)OC(=O)N1Cc2cc([N+](=O)[O-])ccc2C[C@H]1...</td>\n",
       "      <td></td>\n",
       "      <td>CO</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>c1ccc2sc(-c3nccc4ccccc34)cc2c1</td>\n",
       "      <td>84.0</td>\n",
       "      <td></td>\n",
       "      <td>REACTANT:CC(C)(C)OC(=O)N1Cc2cc([N+](=O)[O-])cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>CC(=O)NC[C@H]1CN(c2cc(F)c(N3CCS(=O)(=O)CC3)c(F...</td>\n",
       "      <td></td>\n",
       "      <td>CC(=O)O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CCCCCCCCCCCC(=O)N1CCC[C@H]1C(=O)O</td>\n",
       "      <td>94.0</td>\n",
       "      <td></td>\n",
       "      <td>REACTANT:CC(=O)NC[C@H]1CN(c2cc(F)c(N3CCS(=O)(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>C#C[Si](C)(C)C.FC(F)(F)c1ccc(-c2ccc3ncc(I)n3c2...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>COC(=O)c1nc(Br)cc(Br)c1OCc1ccccc1</td>\n",
       "      <td>89.0</td>\n",
       "      <td></td>\n",
       "      <td>REACTANT:C#C[Si](C)(C)C.FC(F)(F)c1ccc(-c2ccc3n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>CC1CCC(Br)c2ncc(C(=O)O)c(=O)n21.CCCCN.Cl.ClC(C...</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Cl.Cl.Cl.NCCCC[C@H](N)C(=O)NCC(=O)Nc1ccccc1C(=...</td>\n",
       "      <td>31.0</td>\n",
       "      <td></td>\n",
       "      <td>REACTANT:CC1CCC(Br)c2ncc(C(=O)O)c(=O)n21.CCCCN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATALYST                                           REACTANT REAGENT  \\\n",
       "0             CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2ccccc2C12CCCC2           \n",
       "1     [Pd]  CC(C)(C)OC(=O)N1Cc2cc([N+](=O)[O-])ccc2C[C@H]1...           \n",
       "2           CC(=O)NC[C@H]1CN(c2cc(F)c(N3CCS(=O)(=O)CC3)c(F...           \n",
       "3           C#C[Si](C)(C)C.FC(F)(F)c1ccc(-c2ccc3ncc(I)n3c2...           \n",
       "4           CC1CCC(Br)c2ncc(C(=O)O)c(=O)n21.CCCCN.Cl.ClC(C...           \n",
       "\n",
       "   SOLVENT INTERNAL_STANDARD NoData  \\\n",
       "0    ClCCl                            \n",
       "1       CO                            \n",
       "2  CC(=O)O                            \n",
       "3                                     \n",
       "4        O                            \n",
       "\n",
       "                                             PRODUCT  YIELD TEMP  \\\n",
       "0  CC#CN1C(=O)C(C)Oc2ccc(-n3c(=O)cc(C(F)(F)F)[nH]...   98.0        \n",
       "1                     c1ccc2sc(-c3nccc4ccccc34)cc2c1   84.0        \n",
       "2                  CCCCCCCCCCCC(=O)N1CCC[C@H]1C(=O)O   94.0        \n",
       "3                  COC(=O)c1nc(Br)cc(Br)c1OCc1ccccc1   89.0        \n",
       "4  Cl.Cl.Cl.NCCCC[C@H](N)C(=O)NCC(=O)Nc1ccccc1C(=...   31.0        \n",
       "\n",
       "                                               input  \n",
       "0  REACTANT:CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2cccc...  \n",
       "1  REACTANT:CC(C)(C)OC(=O)N1Cc2cc([N+](=O)[O-])cc...  \n",
       "2  REACTANT:CC(=O)NC[C@H]1CN(c2cc(F)c(N3CCS(=O)(=...  \n",
       "3  REACTANT:C#C[Si](C)(C)C.FC(F)(F)c1ccc(-c2ccc3n...  \n",
       "4  REACTANT:CC1CCC(Br)c2ncc(C(=O)O)c(=O)n21.CCCCN...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "OUTPUT_DIR = CFG.output_dir\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=CFG.seed)  \n",
    "    \n",
    "\n",
    "\n",
    "test_ds = pd.read_csv('../../regression-input-valid.csv')\n",
    "display(test_ds.head())\n",
    "\n",
    "# with open(OUTPUT_DIR+'scaler.pkl', 'rb') as f:\n",
    "#     scaler = pickle.load(f)\n",
    "with open(CFG.scaler_path + '/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "test_ds = test_ds[['input', 'YIELD']]\n",
    "\n",
    "test_ds['YIELD'] = scaler.transform(test_ds['YIELD'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe0f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "274b1854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagawa/ZINC-t5 were not used when initializing T5EncoderModel: ['decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.embed_tokens.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'lm_head.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.final_layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load tokenizer\n",
    "try: # load pretrained tokenizer from local directory\n",
    "    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path+'/tokenizer', return_tensors='pt')\n",
    "except: # load pretrained tokenizer from huggingface model hub\n",
    "    CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path, return_tensors='pt')\n",
    "\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text, add_special_tokens=True, max_length=CFG.max_len, padding='max_length', return_offsets_mapping=False, truncation=True, return_attention_mask=True)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.inputs = df['input'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.inputs[item])\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "\n",
    "       \n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.pretrained_model_name_or_path, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            if 't5' in cfg.pretrained_model_name_or_path:\n",
    "                self.model = T5EncoderModel.from_pretrained(CFG.pretrained_model_name_or_path, config=self.config)\n",
    "            else:\n",
    "                self.model = AutoModel.from_pretrained(CFG.pretrained_model_name_or_path, config=self.config)\n",
    "        else:\n",
    "            if True:\n",
    "                self.model = T5EncoderModel.from_pretrained('sagawa/ZINC-t5', config=self.config)\n",
    "            else:\n",
    "                self.model = AutoModel.from_config(self.config)\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        self.fc_dropout1 = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc1 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.fc_dropout2 = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc2 = nn.Linear(self.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        output = self.fc1(self.fc_dropout1(last_hidden_states)[:, 0, :].view(-1, self.config.hidden_size))\n",
    "        output = self.fc2(self.fc_dropout2(output))\n",
    "        return output\n",
    "    \n",
    "\n",
    "    \n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "test_dataset = TestDataset(CFG, test_ds)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "\n",
    "model = RegressionModel(CFG, config_path=CFG.model_name_or_path + '/config.pth', pretrained=False)\n",
    "state = torch.load(CFG.model_name_or_path + '/ZINC-t5_best.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce422ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d10e80454d4499d81725631a4c4bf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63496447],\n",
       "       [0.88279617],\n",
       "       [0.6655084 ],\n",
       "       [0.62741876],\n",
       "       [0.66845524],\n",
       "       [0.6833414 ],\n",
       "       [0.6394496 ],\n",
       "       [0.59902155],\n",
       "       [0.5515357 ],\n",
       "       [0.35360926],\n",
       "       [0.6612506 ],\n",
       "       [0.6536778 ],\n",
       "       [0.17100209],\n",
       "       [0.76545405],\n",
       "       [0.55786943],\n",
       "       [0.56836164],\n",
       "       [0.64050794],\n",
       "       [0.507064  ],\n",
       "       [0.62926114],\n",
       "       [0.6844653 ],\n",
       "       [0.8316356 ],\n",
       "       [0.40217593],\n",
       "       [0.6495297 ],\n",
       "       [0.6949899 ],\n",
       "       [0.5289475 ],\n",
       "       [0.66726243],\n",
       "       [0.5060371 ],\n",
       "       [0.3532765 ],\n",
       "       [0.5428307 ],\n",
       "       [0.6304369 ],\n",
       "       [0.6990107 ],\n",
       "       [0.37147972],\n",
       "       [0.5991924 ],\n",
       "       [0.46930087],\n",
       "       [0.7791816 ],\n",
       "       [0.5646428 ],\n",
       "       [0.44927165],\n",
       "       [0.72419083],\n",
       "       [0.7670516 ],\n",
       "       [0.6665206 ],\n",
       "       [0.5843389 ],\n",
       "       [0.6230478 ],\n",
       "       [0.52603865],\n",
       "       [0.62091744],\n",
       "       [0.5787926 ],\n",
       "       [0.7471688 ],\n",
       "       [0.5209596 ],\n",
       "       [0.4488422 ],\n",
       "       [0.74226034],\n",
       "       [0.8205104 ],\n",
       "       [0.6134435 ],\n",
       "       [0.47767025],\n",
       "       [0.628157  ],\n",
       "       [0.50242543],\n",
       "       [0.49608296],\n",
       "       [0.76701605],\n",
       "       [0.77321243],\n",
       "       [0.34903452],\n",
       "       [0.34096423],\n",
       "       [0.52718043],\n",
       "       [0.17143148],\n",
       "       [0.6486653 ],\n",
       "       [0.6332706 ],\n",
       "       [0.30404094],\n",
       "       [0.5482216 ],\n",
       "       [0.6131575 ],\n",
       "       [0.65358686],\n",
       "       [0.459796  ],\n",
       "       [0.6486771 ],\n",
       "       [0.48906478],\n",
       "       [0.50773084],\n",
       "       [0.22245815],\n",
       "       [0.79445755],\n",
       "       [0.5419755 ],\n",
       "       [0.5496012 ],\n",
       "       [0.3998285 ],\n",
       "       [0.4342999 ],\n",
       "       [0.5398729 ],\n",
       "       [0.56160223],\n",
       "       [0.5874808 ],\n",
       "       [0.6149919 ],\n",
       "       [0.65286803],\n",
       "       [0.589414  ],\n",
       "       [0.6879808 ],\n",
       "       [0.4472185 ],\n",
       "       [0.3627668 ],\n",
       "       [0.6423919 ],\n",
       "       [0.6006601 ],\n",
       "       [0.549886  ],\n",
       "       [0.25036973],\n",
       "       [0.08880114],\n",
       "       [0.62237716],\n",
       "       [0.4852957 ],\n",
       "       [0.66447794],\n",
       "       [0.3169444 ],\n",
       "       [0.68545055],\n",
       "       [0.22825974],\n",
       "       [0.27282345],\n",
       "       [0.73262274],\n",
       "       [0.60706794],\n",
       "       [0.5640464 ],\n",
       "       [0.5838206 ],\n",
       "       [0.7628584 ],\n",
       "       [0.4797693 ],\n",
       "       [0.7217498 ],\n",
       "       [0.5001627 ],\n",
       "       [0.7376348 ],\n",
       "       [0.66202354],\n",
       "       [0.09870727],\n",
       "       [0.577813  ],\n",
       "       [0.7640655 ],\n",
       "       [0.63899875],\n",
       "       [0.24665678],\n",
       "       [0.7087145 ],\n",
       "       [0.6537826 ],\n",
       "       [0.3291788 ],\n",
       "       [0.7073144 ],\n",
       "       [0.60427284],\n",
       "       [0.5903928 ],\n",
       "       [0.620661  ],\n",
       "       [0.44352224],\n",
       "       [0.5826287 ],\n",
       "       [0.63142145],\n",
       "       [0.5452665 ],\n",
       "       [0.698827  ],\n",
       "       [0.71206963],\n",
       "       [0.33989665],\n",
       "       [0.3524648 ],\n",
       "       [0.49722788],\n",
       "       [0.56335723],\n",
       "       [0.5870024 ],\n",
       "       [0.7510607 ],\n",
       "       [0.68521845],\n",
       "       [0.7136855 ],\n",
       "       [0.4912641 ],\n",
       "       [0.67311895],\n",
       "       [0.5670992 ],\n",
       "       [0.549183  ],\n",
       "       [0.49084482],\n",
       "       [0.73053694],\n",
       "       [0.7202871 ],\n",
       "       [0.5559498 ],\n",
       "       [0.64531434],\n",
       "       [0.6608422 ],\n",
       "       [0.60414195],\n",
       "       [0.6289332 ],\n",
       "       [0.85712457],\n",
       "       [0.6559261 ],\n",
       "       [0.54534864],\n",
       "       [0.6352136 ],\n",
       "       [0.20048212],\n",
       "       [0.6047071 ],\n",
       "       [0.65099454],\n",
       "       [0.45465383],\n",
       "       [0.62059927],\n",
       "       [0.6541709 ],\n",
       "       [0.6429516 ],\n",
       "       [0.5656103 ],\n",
       "       [0.6759453 ],\n",
       "       [0.73320246],\n",
       "       [0.6370126 ],\n",
       "       [0.571496  ],\n",
       "       [0.5209565 ],\n",
       "       [0.5836123 ],\n",
       "       [0.46412095],\n",
       "       [0.47593072],\n",
       "       [0.44973856],\n",
       "       [0.6373085 ],\n",
       "       [0.49372634],\n",
       "       [0.75814223],\n",
       "       [0.67573273],\n",
       "       [0.8175039 ],\n",
       "       [0.61046636],\n",
       "       [0.6959759 ],\n",
       "       [0.49780473],\n",
       "       [0.5937687 ],\n",
       "       [0.6229205 ],\n",
       "       [0.57874465],\n",
       "       [0.6842358 ],\n",
       "       [0.5245918 ],\n",
       "       [0.3280522 ],\n",
       "       [0.54185593],\n",
       "       [0.5763029 ],\n",
       "       [0.18977782],\n",
       "       [0.8197408 ],\n",
       "       [0.48928183],\n",
       "       [0.6698195 ],\n",
       "       [0.5541471 ],\n",
       "       [0.28971264],\n",
       "       [0.7916151 ],\n",
       "       [0.6223397 ],\n",
       "       [0.512594  ],\n",
       "       [0.5910239 ],\n",
       "       [0.6001141 ],\n",
       "       [0.54808843],\n",
       "       [0.51968616],\n",
       "       [0.52637035],\n",
       "       [0.52767944],\n",
       "       [0.57109904],\n",
       "       [0.6818521 ],\n",
       "       [0.59693706],\n",
       "       [0.798432  ],\n",
       "       [0.83794284],\n",
       "       [0.5160221 ],\n",
       "       [0.5572351 ],\n",
       "       [0.5728693 ],\n",
       "       [0.6456573 ],\n",
       "       [0.5785223 ],\n",
       "       [0.6930442 ],\n",
       "       [0.6061206 ],\n",
       "       [0.7165086 ],\n",
       "       [0.52444077],\n",
       "       [0.73832333],\n",
       "       [0.7112342 ],\n",
       "       [0.7225969 ],\n",
       "       [0.5362325 ],\n",
       "       [0.72269154],\n",
       "       [0.6169094 ],\n",
       "       [0.43341967],\n",
       "       [0.63356817],\n",
       "       [0.58953416],\n",
       "       [0.5030196 ],\n",
       "       [0.8356395 ],\n",
       "       [0.40418634],\n",
       "       [0.44012097],\n",
       "       [0.5989182 ],\n",
       "       [0.7419846 ],\n",
       "       [0.82458425],\n",
       "       [0.54615116],\n",
       "       [0.6663523 ],\n",
       "       [0.69257045],\n",
       "       [0.5832796 ],\n",
       "       [0.84325457],\n",
       "       [0.5709069 ],\n",
       "       [0.62079084],\n",
       "       [0.46491727],\n",
       "       [0.6437948 ],\n",
       "       [0.38006946],\n",
       "       [0.6601671 ],\n",
       "       [0.73531926],\n",
       "       [0.68706954],\n",
       "       [0.7500677 ],\n",
       "       [0.61550474],\n",
       "       [0.6690452 ],\n",
       "       [0.7904748 ],\n",
       "       [0.5700675 ],\n",
       "       [0.68697035],\n",
       "       [0.7763088 ],\n",
       "       [0.68708813],\n",
       "       [0.17099547],\n",
       "       [0.60793054],\n",
       "       [0.80106294],\n",
       "       [0.7079365 ],\n",
       "       [0.476679  ],\n",
       "       [0.44431677],\n",
       "       [0.42983076],\n",
       "       [0.6479937 ],\n",
       "       [0.651611  ],\n",
       "       [0.65371346],\n",
       "       [0.50142395],\n",
       "       [0.569595  ],\n",
       "       [0.6262933 ],\n",
       "       [0.28739792],\n",
       "       [0.5960885 ],\n",
       "       [0.8158877 ],\n",
       "       [0.78579366],\n",
       "       [0.39489025],\n",
       "       [0.65155137],\n",
       "       [0.25669727],\n",
       "       [0.37840354],\n",
       "       [0.36946738],\n",
       "       [0.3023375 ],\n",
       "       [0.4898436 ],\n",
       "       [0.639675  ],\n",
       "       [0.51969784],\n",
       "       [0.6488749 ],\n",
       "       [0.7038034 ],\n",
       "       [0.46157837],\n",
       "       [0.5955875 ],\n",
       "       [0.71406364],\n",
       "       [0.5192034 ],\n",
       "       [0.7862345 ],\n",
       "       [0.73696685],\n",
       "       [0.6869972 ],\n",
       "       [0.77265716],\n",
       "       [0.6538168 ],\n",
       "       [0.51682127],\n",
       "       [0.59537804],\n",
       "       [0.6126914 ],\n",
       "       [0.5362259 ],\n",
       "       [0.33693257],\n",
       "       [0.62279284],\n",
       "       [0.45586511],\n",
       "       [0.5066298 ],\n",
       "       [0.36148152],\n",
       "       [0.71698606],\n",
       "       [0.1645121 ],\n",
       "       [0.8013176 ],\n",
       "       [0.6493434 ],\n",
       "       [0.7277235 ],\n",
       "       [0.679587  ],\n",
       "       [0.4451106 ],\n",
       "       [0.45534858],\n",
       "       [0.24888746],\n",
       "       [0.59813035],\n",
       "       [0.4747004 ],\n",
       "       [0.43023103],\n",
       "       [0.61721754],\n",
       "       [0.76938665],\n",
       "       [0.650725  ],\n",
       "       [0.88834846],\n",
       "       [0.4523945 ],\n",
       "       [0.78235686],\n",
       "       [0.575827  ],\n",
       "       [0.23692249],\n",
       "       [0.5559025 ],\n",
       "       [0.706069  ],\n",
       "       [0.30337647],\n",
       "       [0.7721162 ],\n",
       "       [0.6562489 ],\n",
       "       [0.5605577 ],\n",
       "       [0.64911616],\n",
       "       [0.55136967],\n",
       "       [0.80415046],\n",
       "       [0.68506145],\n",
       "       [0.21637431],\n",
       "       [0.4834575 ],\n",
       "       [0.82429945],\n",
       "       [0.59019566],\n",
       "       [0.7461108 ],\n",
       "       [0.77455366],\n",
       "       [0.6599848 ],\n",
       "       [0.74746644],\n",
       "       [0.6330216 ],\n",
       "       [0.5369961 ],\n",
       "       [0.7866261 ],\n",
       "       [0.71967447],\n",
       "       [0.67333674],\n",
       "       [0.57845247],\n",
       "       [0.5080905 ],\n",
       "       [0.6645169 ],\n",
       "       [0.72678554],\n",
       "       [0.5327703 ],\n",
       "       [0.6749499 ],\n",
       "       [0.43778035],\n",
       "       [0.30476376],\n",
       "       [0.6495652 ],\n",
       "       [0.5396347 ],\n",
       "       [0.63850904],\n",
       "       [0.5722295 ],\n",
       "       [0.65609133],\n",
       "       [0.8547827 ],\n",
       "       [0.7830912 ],\n",
       "       [0.5917983 ],\n",
       "       [0.55680287],\n",
       "       [0.41531765],\n",
       "       [0.39781997],\n",
       "       [0.30431762],\n",
       "       [0.5613321 ],\n",
       "       [0.67937946],\n",
       "       [0.27083874],\n",
       "       [0.23605102],\n",
       "       [0.42609176],\n",
       "       [0.66680527],\n",
       "       [0.51654065],\n",
       "       [0.75376236],\n",
       "       [0.7635399 ],\n",
       "       [0.5441178 ],\n",
       "       [0.6365279 ],\n",
       "       [0.7047688 ],\n",
       "       [0.71573675],\n",
       "       [0.6609613 ],\n",
       "       [0.6766577 ],\n",
       "       [0.63014424],\n",
       "       [0.5239078 ],\n",
       "       [0.5232235 ],\n",
       "       [0.54304457],\n",
       "       [0.59131074],\n",
       "       [0.6551919 ],\n",
       "       [0.6893958 ],\n",
       "       [0.25518295],\n",
       "       [0.4858339 ],\n",
       "       [0.46304044],\n",
       "       [0.5835465 ],\n",
       "       [0.6911565 ],\n",
       "       [0.24658297],\n",
       "       [0.67904055],\n",
       "       [0.6663952 ],\n",
       "       [0.5889541 ],\n",
       "       [0.7299428 ],\n",
       "       [0.5404061 ],\n",
       "       [0.51120746],\n",
       "       [0.613387  ],\n",
       "       [0.6974567 ],\n",
       "       [0.5546727 ],\n",
       "       [0.56510377],\n",
       "       [0.2223703 ],\n",
       "       [0.10867777],\n",
       "       [0.8568928 ],\n",
       "       [0.6602732 ],\n",
       "       [0.6645416 ],\n",
       "       [0.522347  ],\n",
       "       [0.9196738 ],\n",
       "       [0.38081205],\n",
       "       [0.6779431 ],\n",
       "       [0.7054473 ],\n",
       "       [0.6901021 ],\n",
       "       [0.5212256 ],\n",
       "       [0.50866485],\n",
       "       [0.62623763],\n",
       "       [0.40991816],\n",
       "       [0.870481  ],\n",
       "       [0.6974164 ],\n",
       "       [0.67445564],\n",
       "       [0.6334635 ],\n",
       "       [0.6619468 ],\n",
       "       [0.5979562 ],\n",
       "       [0.22245815],\n",
       "       [0.5889871 ],\n",
       "       [0.43504646],\n",
       "       [0.6428336 ],\n",
       "       [0.7530043 ],\n",
       "       [0.54609835],\n",
       "       [0.63034976],\n",
       "       [0.5031811 ],\n",
       "       [0.5027944 ],\n",
       "       [0.68859696],\n",
       "       [0.51071787],\n",
       "       [0.588989  ],\n",
       "       [0.73531306],\n",
       "       [0.699911  ],\n",
       "       [0.6144692 ],\n",
       "       [0.78984094],\n",
       "       [0.489567  ],\n",
       "       [0.62926376],\n",
       "       [0.6073165 ],\n",
       "       [0.70258915],\n",
       "       [0.37969002],\n",
       "       [0.447823  ],\n",
       "       [0.66537285],\n",
       "       [0.6066433 ],\n",
       "       [0.5053543 ],\n",
       "       [0.37097752],\n",
       "       [0.64721024],\n",
       "       [0.7558056 ],\n",
       "       [0.57442725],\n",
       "       [0.3145877 ],\n",
       "       [0.6092355 ],\n",
       "       [0.6346817 ],\n",
       "       [0.4361605 ],\n",
       "       [0.7613491 ],\n",
       "       [0.7468319 ],\n",
       "       [0.58574677],\n",
       "       [0.4048614 ],\n",
       "       [0.45740774],\n",
       "       [0.48717356],\n",
       "       [0.5955957 ],\n",
       "       [0.56915915],\n",
       "       [0.3459325 ],\n",
       "       [0.4619744 ],\n",
       "       [0.7610247 ],\n",
       "       [0.58632576],\n",
       "       [0.66596556],\n",
       "       [0.6489036 ],\n",
       "       [0.51535046],\n",
       "       [0.54335153],\n",
       "       [0.69846606],\n",
       "       [0.687659  ],\n",
       "       [0.8067417 ],\n",
       "       [0.49092922],\n",
       "       [0.7675127 ],\n",
       "       [0.6559881 ],\n",
       "       [0.23657024],\n",
       "       [0.55220175],\n",
       "       [0.8767992 ],\n",
       "       [0.5990881 ],\n",
       "       [0.5240655 ],\n",
       "       [0.38601372],\n",
       "       [0.7146214 ],\n",
       "       [0.6970155 ],\n",
       "       [0.6320243 ],\n",
       "       [0.44102433],\n",
       "       [0.55765784],\n",
       "       [0.7162204 ],\n",
       "       [0.68482447],\n",
       "       [0.5505351 ],\n",
       "       [0.5210276 ],\n",
       "       [0.7994909 ],\n",
       "       [0.7316494 ],\n",
       "       [0.43674314],\n",
       "       [0.69182956],\n",
       "       [0.59622025],\n",
       "       [0.66457593],\n",
       "       [0.55112314],\n",
       "       [0.33903632],\n",
       "       [0.71682715],\n",
       "       [0.7897562 ],\n",
       "       [0.65931857],\n",
       "       [0.4150425 ],\n",
       "       [0.45141384]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = inference_fn(test_loader, model, device)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e0cc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c32e9f12329464dbdb5ccbbcc53d613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6189771 ],\n",
       "       [0.59322965],\n",
       "       [0.5555079 ],\n",
       "       [0.5918845 ],\n",
       "       [0.56737405],\n",
       "       [0.5985358 ],\n",
       "       [0.58216214],\n",
       "       [0.60153526],\n",
       "       [0.679618  ],\n",
       "       [0.5753029 ],\n",
       "       [0.62062585],\n",
       "       [0.5948294 ],\n",
       "       [0.580694  ],\n",
       "       [0.5894024 ],\n",
       "       [0.6379183 ],\n",
       "       [0.5222249 ],\n",
       "       [0.5884903 ],\n",
       "       [0.547188  ],\n",
       "       [0.58316964],\n",
       "       [0.68957883],\n",
       "       [0.61838716],\n",
       "       [0.564923  ],\n",
       "       [0.73818123],\n",
       "       [0.5935827 ],\n",
       "       [0.6658546 ],\n",
       "       [0.537824  ],\n",
       "       [0.66204053],\n",
       "       [0.7076806 ],\n",
       "       [0.60698384],\n",
       "       [0.6153175 ],\n",
       "       [0.63155526],\n",
       "       [0.48151118],\n",
       "       [0.54806495],\n",
       "       [0.6024049 ],\n",
       "       [0.6077259 ],\n",
       "       [0.59931755],\n",
       "       [0.58332306],\n",
       "       [0.6408519 ],\n",
       "       [0.5897757 ],\n",
       "       [0.56226   ],\n",
       "       [0.53998065],\n",
       "       [0.5712919 ],\n",
       "       [0.59482294],\n",
       "       [0.669676  ],\n",
       "       [0.5027402 ],\n",
       "       [0.5810004 ],\n",
       "       [0.5921702 ],\n",
       "       [0.7225131 ],\n",
       "       [0.6000999 ],\n",
       "       [0.52649146],\n",
       "       [0.5567972 ],\n",
       "       [0.49489337],\n",
       "       [0.5845639 ],\n",
       "       [0.5417519 ],\n",
       "       [0.7008844 ],\n",
       "       [0.58680725],\n",
       "       [0.62719953],\n",
       "       [0.5770614 ],\n",
       "       [0.5091909 ],\n",
       "       [0.7095023 ],\n",
       "       [0.6291644 ],\n",
       "       [0.57850516],\n",
       "       [0.6372873 ],\n",
       "       [0.6454788 ],\n",
       "       [0.57260203],\n",
       "       [0.6494685 ],\n",
       "       [0.6050161 ],\n",
       "       [0.4635384 ],\n",
       "       [0.5401207 ],\n",
       "       [0.5936654 ],\n",
       "       [0.5966336 ],\n",
       "       [0.5500477 ],\n",
       "       [0.6176453 ],\n",
       "       [0.55129474],\n",
       "       [0.65525824],\n",
       "       [0.75316966],\n",
       "       [0.61554193],\n",
       "       [0.6370266 ],\n",
       "       [0.65160304],\n",
       "       [0.6079511 ],\n",
       "       [0.53858376],\n",
       "       [0.6893602 ],\n",
       "       [0.62544715],\n",
       "       [0.5994969 ],\n",
       "       [0.6277214 ],\n",
       "       [0.542185  ],\n",
       "       [0.5860857 ],\n",
       "       [0.6113644 ],\n",
       "       [0.62004524],\n",
       "       [0.6586917 ],\n",
       "       [0.6448063 ],\n",
       "       [0.5736811 ],\n",
       "       [0.6160719 ],\n",
       "       [0.58257407],\n",
       "       [0.570612  ],\n",
       "       [0.5799327 ],\n",
       "       [0.60656625],\n",
       "       [0.42624605],\n",
       "       [0.58786047],\n",
       "       [0.55585915],\n",
       "       [0.6912221 ],\n",
       "       [0.5490392 ],\n",
       "       [0.61031663],\n",
       "       [0.5941862 ],\n",
       "       [0.52876437],\n",
       "       [0.6218725 ],\n",
       "       [0.64764893],\n",
       "       [0.564326  ],\n",
       "       [0.6473089 ],\n",
       "       [0.66345316],\n",
       "       [0.6587772 ],\n",
       "       [0.62191224],\n",
       "       [0.6346879 ],\n",
       "       [0.6546921 ],\n",
       "       [0.49532446],\n",
       "       [0.63009363],\n",
       "       [0.5956878 ],\n",
       "       [0.58120334],\n",
       "       [0.6177721 ],\n",
       "       [0.584035  ],\n",
       "       [0.6581063 ],\n",
       "       [0.59420806],\n",
       "       [0.56787217],\n",
       "       [0.63307774],\n",
       "       [0.67095476],\n",
       "       [0.6424967 ],\n",
       "       [0.59720707],\n",
       "       [0.5794355 ],\n",
       "       [0.5669964 ],\n",
       "       [0.5965865 ],\n",
       "       [0.61978257],\n",
       "       [0.5941481 ],\n",
       "       [0.6108931 ],\n",
       "       [0.5423255 ],\n",
       "       [0.5454031 ],\n",
       "       [0.5879981 ],\n",
       "       [0.54340774],\n",
       "       [0.60340995],\n",
       "       [0.5718551 ],\n",
       "       [0.59723467],\n",
       "       [0.6151379 ],\n",
       "       [0.6368845 ],\n",
       "       [0.57306534],\n",
       "       [0.63661736],\n",
       "       [0.6938923 ],\n",
       "       [0.6359622 ],\n",
       "       [0.5946548 ],\n",
       "       [0.57845366],\n",
       "       [0.6897519 ],\n",
       "       [0.55414784],\n",
       "       [0.5898027 ],\n",
       "       [0.7086615 ],\n",
       "       [0.6616002 ],\n",
       "       [0.5953055 ],\n",
       "       [0.6475429 ],\n",
       "       [0.67928237],\n",
       "       [0.57492536],\n",
       "       [0.673543  ],\n",
       "       [0.5867408 ],\n",
       "       [0.5883594 ],\n",
       "       [0.544257  ],\n",
       "       [0.64259034],\n",
       "       [0.5983098 ],\n",
       "       [0.683397  ],\n",
       "       [0.57562274],\n",
       "       [0.59105664],\n",
       "       [0.5082683 ],\n",
       "       [0.60315937],\n",
       "       [0.67417115],\n",
       "       [0.63245034],\n",
       "       [0.6706201 ],\n",
       "       [0.6284828 ],\n",
       "       [0.5871055 ],\n",
       "       [0.6545163 ],\n",
       "       [0.6373074 ],\n",
       "       [0.5873228 ],\n",
       "       [0.59625363],\n",
       "       [0.6707943 ],\n",
       "       [0.74553174],\n",
       "       [0.63813573],\n",
       "       [0.62203175],\n",
       "       [0.588023  ],\n",
       "       [0.56762403],\n",
       "       [0.61681825],\n",
       "       [0.6289929 ],\n",
       "       [0.6798008 ],\n",
       "       [0.56914186],\n",
       "       [0.5807367 ],\n",
       "       [0.57262176],\n",
       "       [0.5961071 ],\n",
       "       [0.62776065],\n",
       "       [0.55988705],\n",
       "       [0.60319585],\n",
       "       [0.57758975],\n",
       "       [0.57681537],\n",
       "       [0.5414761 ],\n",
       "       [0.5709372 ],\n",
       "       [0.5332294 ],\n",
       "       [0.6999715 ],\n",
       "       [0.55773014],\n",
       "       [0.5524592 ],\n",
       "       [0.6572673 ],\n",
       "       [0.6626811 ],\n",
       "       [0.6562443 ],\n",
       "       [0.5779836 ],\n",
       "       [0.5469276 ],\n",
       "       [0.56448674],\n",
       "       [0.5844988 ],\n",
       "       [0.64813954],\n",
       "       [0.5748674 ],\n",
       "       [0.54653627],\n",
       "       [0.5902496 ],\n",
       "       [0.5950803 ],\n",
       "       [0.76224935],\n",
       "       [0.6085973 ],\n",
       "       [0.59575415],\n",
       "       [0.7030523 ],\n",
       "       [0.60899776],\n",
       "       [0.5596945 ],\n",
       "       [0.61708635],\n",
       "       [0.5624026 ],\n",
       "       [0.66835934],\n",
       "       [0.5467684 ],\n",
       "       [0.56854236],\n",
       "       [0.5436908 ],\n",
       "       [0.5727985 ],\n",
       "       [0.56441945],\n",
       "       [0.59757066],\n",
       "       [0.5924636 ],\n",
       "       [0.70700574],\n",
       "       [0.61362255],\n",
       "       [0.5851155 ],\n",
       "       [0.5742311 ],\n",
       "       [0.5969789 ],\n",
       "       [0.6474996 ],\n",
       "       [0.66072685],\n",
       "       [0.5716798 ],\n",
       "       [0.5668791 ],\n",
       "       [0.6382171 ],\n",
       "       [0.6771656 ],\n",
       "       [0.70959336],\n",
       "       [0.5684033 ],\n",
       "       [0.60993266],\n",
       "       [0.53382015],\n",
       "       [0.7058919 ],\n",
       "       [0.5616309 ],\n",
       "       [0.61072826],\n",
       "       [0.6791939 ],\n",
       "       [0.56038195],\n",
       "       [0.65810096],\n",
       "       [0.5927689 ],\n",
       "       [0.5352867 ],\n",
       "       [0.60721445],\n",
       "       [0.5741045 ],\n",
       "       [0.58813405],\n",
       "       [0.6294274 ],\n",
       "       [0.62946767],\n",
       "       [0.5826659 ],\n",
       "       [0.5546676 ],\n",
       "       [0.5658774 ],\n",
       "       [0.5419335 ],\n",
       "       [0.6353143 ],\n",
       "       [0.58667654],\n",
       "       [0.58185524],\n",
       "       [0.6110038 ],\n",
       "       [0.59468734],\n",
       "       [0.5919397 ],\n",
       "       [0.6818269 ],\n",
       "       [0.75583434],\n",
       "       [0.57064813],\n",
       "       [0.67712533],\n",
       "       [0.6188884 ],\n",
       "       [0.5847085 ],\n",
       "       [0.62078583],\n",
       "       [0.59602   ],\n",
       "       [0.65403944],\n",
       "       [0.587803  ],\n",
       "       [0.5615558 ],\n",
       "       [0.59007174],\n",
       "       [0.6786676 ],\n",
       "       [0.5509604 ],\n",
       "       [0.5910268 ],\n",
       "       [0.5605225 ],\n",
       "       [0.72798437],\n",
       "       [0.628802  ],\n",
       "       [0.6099358 ],\n",
       "       [0.5924517 ],\n",
       "       [0.58039516],\n",
       "       [0.5840646 ],\n",
       "       [0.66286767],\n",
       "       [0.54953164],\n",
       "       [0.68071604],\n",
       "       [0.6796837 ],\n",
       "       [0.6270131 ],\n",
       "       [0.69824594],\n",
       "       [0.6585584 ],\n",
       "       [0.6447004 ],\n",
       "       [0.5903885 ],\n",
       "       [0.5566793 ],\n",
       "       [0.5578408 ],\n",
       "       [0.6627075 ],\n",
       "       [0.577193  ],\n",
       "       [0.65433085],\n",
       "       [0.63927907],\n",
       "       [0.65188056],\n",
       "       [0.54258305],\n",
       "       [0.5396312 ],\n",
       "       [0.66894084],\n",
       "       [0.59473604],\n",
       "       [0.64844614],\n",
       "       [0.6750875 ],\n",
       "       [0.5840153 ],\n",
       "       [0.6205086 ],\n",
       "       [0.6058129 ],\n",
       "       [0.60320014],\n",
       "       [0.65268856],\n",
       "       [0.6167938 ],\n",
       "       [0.5842009 ],\n",
       "       [0.58061725],\n",
       "       [0.5719884 ],\n",
       "       [0.57073087],\n",
       "       [0.60244644],\n",
       "       [0.5587229 ],\n",
       "       [0.61599845],\n",
       "       [0.6157874 ],\n",
       "       [0.5691171 ],\n",
       "       [0.5611832 ],\n",
       "       [0.52415144],\n",
       "       [0.44655013],\n",
       "       [0.6551057 ],\n",
       "       [0.61808   ],\n",
       "       [0.62153834],\n",
       "       [0.62182426],\n",
       "       [0.60273075],\n",
       "       [0.681631  ],\n",
       "       [0.6858193 ],\n",
       "       [0.59614646],\n",
       "       [0.6323251 ],\n",
       "       [0.69313234],\n",
       "       [0.52482116],\n",
       "       [0.7095005 ],\n",
       "       [0.58498085],\n",
       "       [0.58868253],\n",
       "       [0.64335966],\n",
       "       [0.6124574 ],\n",
       "       [0.6484248 ],\n",
       "       [0.73139614],\n",
       "       [0.58816534],\n",
       "       [0.6588554 ],\n",
       "       [0.4835323 ],\n",
       "       [0.5552163 ],\n",
       "       [0.59372026],\n",
       "       [0.6165759 ],\n",
       "       [0.6116972 ],\n",
       "       [0.6727944 ],\n",
       "       [0.6334346 ],\n",
       "       [0.6825639 ],\n",
       "       [0.6514684 ],\n",
       "       [0.5703714 ],\n",
       "       [0.576659  ],\n",
       "       [0.48141137],\n",
       "       [0.6701464 ],\n",
       "       [0.59221756],\n",
       "       [0.5907845 ],\n",
       "       [0.5928784 ],\n",
       "       [0.5854167 ],\n",
       "       [0.66654766],\n",
       "       [0.53388363],\n",
       "       [0.5565546 ],\n",
       "       [0.5852789 ],\n",
       "       [0.53653204],\n",
       "       [0.568944  ],\n",
       "       [0.63016784],\n",
       "       [0.6214906 ],\n",
       "       [0.5717154 ],\n",
       "       [0.5887453 ],\n",
       "       [0.60760623],\n",
       "       [0.50273037],\n",
       "       [0.5497895 ],\n",
       "       [0.6256407 ],\n",
       "       [0.6249515 ],\n",
       "       [0.56810135],\n",
       "       [0.6169444 ],\n",
       "       [0.53746927],\n",
       "       [0.7249622 ],\n",
       "       [0.54002845],\n",
       "       [0.59421337],\n",
       "       [0.54874927],\n",
       "       [0.5978971 ],\n",
       "       [0.5977214 ],\n",
       "       [0.6103515 ],\n",
       "       [0.5792949 ],\n",
       "       [0.562686  ],\n",
       "       [0.566885  ],\n",
       "       [0.5866239 ],\n",
       "       [0.5684924 ],\n",
       "       [0.6009415 ],\n",
       "       [0.5753735 ],\n",
       "       [0.58143   ],\n",
       "       [0.64920616],\n",
       "       [0.5946124 ],\n",
       "       [0.587892  ],\n",
       "       [0.58492416],\n",
       "       [0.59899265],\n",
       "       [0.65329385],\n",
       "       [0.619145  ],\n",
       "       [0.588821  ],\n",
       "       [0.53515965],\n",
       "       [0.6445841 ],\n",
       "       [0.6726533 ],\n",
       "       [0.6842321 ],\n",
       "       [0.6219135 ],\n",
       "       [0.76810604],\n",
       "       [0.6110801 ],\n",
       "       [0.58358526],\n",
       "       [0.6160224 ],\n",
       "       [0.6521096 ],\n",
       "       [0.5500477 ],\n",
       "       [0.56578046],\n",
       "       [0.7148735 ],\n",
       "       [0.6006377 ],\n",
       "       [0.55875367],\n",
       "       [0.61988634],\n",
       "       [0.56810254],\n",
       "       [0.6071492 ],\n",
       "       [0.592901  ],\n",
       "       [0.59229416],\n",
       "       [0.70732516],\n",
       "       [0.62666786],\n",
       "       [0.5547119 ],\n",
       "       [0.64940375],\n",
       "       [0.6877213 ],\n",
       "       [0.707859  ],\n",
       "       [0.64577144],\n",
       "       [0.6066826 ],\n",
       "       [0.67150086],\n",
       "       [0.5490366 ],\n",
       "       [0.6628608 ],\n",
       "       [0.66718453],\n",
       "       [0.64534026],\n",
       "       [0.64077264],\n",
       "       [0.61647356],\n",
       "       [0.67140746],\n",
       "       [0.57876897],\n",
       "       [0.6128544 ],\n",
       "       [0.5846468 ],\n",
       "       [0.6116938 ],\n",
       "       [0.5497188 ],\n",
       "       [0.7159277 ],\n",
       "       [0.6535225 ],\n",
       "       [0.6157703 ],\n",
       "       [0.5201596 ],\n",
       "       [0.67621654],\n",
       "       [0.57712483],\n",
       "       [0.575774  ],\n",
       "       [0.5716427 ],\n",
       "       [0.6203411 ],\n",
       "       [0.6174585 ],\n",
       "       [0.5545936 ],\n",
       "       [0.59318405],\n",
       "       [0.6171095 ],\n",
       "       [0.556513  ],\n",
       "       [0.62069917],\n",
       "       [0.5645074 ],\n",
       "       [0.57232696],\n",
       "       [0.55433774],\n",
       "       [0.61866647],\n",
       "       [0.63020366],\n",
       "       [0.64866376],\n",
       "       [0.59225357],\n",
       "       [0.640531  ],\n",
       "       [0.6997664 ],\n",
       "       [0.5924215 ],\n",
       "       [0.5745837 ],\n",
       "       [0.65610653],\n",
       "       [0.5829958 ],\n",
       "       [0.5699273 ],\n",
       "       [0.644126  ],\n",
       "       [0.49992695],\n",
       "       [0.6374256 ],\n",
       "       [0.57698184],\n",
       "       [0.6099777 ],\n",
       "       [0.6279177 ],\n",
       "       [0.5128007 ],\n",
       "       [0.5459127 ],\n",
       "       [0.54594886],\n",
       "       [0.6740437 ],\n",
       "       [0.61862797],\n",
       "       [0.5463561 ],\n",
       "       [0.5839691 ],\n",
       "       [0.61306936],\n",
       "       [0.6348403 ],\n",
       "       [0.66364133],\n",
       "       [0.6309284 ],\n",
       "       [0.5822815 ],\n",
       "       [0.5772284 ],\n",
       "       [0.66541106],\n",
       "       [0.7085803 ],\n",
       "       [0.57503945],\n",
       "       [0.63804024]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = inference_fn(test_loader, model, device)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25fde97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REACTANT:CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2cccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input\n",
       "0  REACTANT:CCN(CC)CC.CCOC(=O)Cl.NCCC1(O)CCc2cccc"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29df371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = pd.read_csv(CFG.data)\n",
    "# if CFG.debug:\n",
    "#     df = df[:1000]\n",
    "# df = df.dropna().reset_index(drop=True)\n",
    "df = df[~df['YIELD'].isna()]\n",
    "for col in ['CATALYST', 'REACTANT', 'REAGENT', 'SOLVENT', 'INTERNAL_STANDARD', 'NoData','PRODUCT', 'YIELD', 'TEMP']:\n",
    "    df[col] = df[col].fillna(' ')\n",
    "# df['input'] = 'REACTANT:' + df['REACTANT'] + 'PRODUCT:' + df['PRODUCT'] + 'CATALYST:' + df['CATALYST'] + 'REAGENT:' + df['REAGENT'] + 'SOLVENT:' + df['SOLVENT'] + 'NoData:' + df['NoData']\n",
    "df['input'] = 'REACTANT:' + df['REACTANT'] + 'PRODUCT:' + df['PRODUCT'] + 'CATALYST:' + df['CATALYST']\n",
    "train_ds = df[:int(len(df)*0.8)]\n",
    "train_ds = train_ds[train_ds['YIELD']<df['YIELD'].quantile(0.999)].reset_index(drop=True)\n",
    "valid_ds = df[int(len(df)*0.8):].reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_ds['YIELD'] = scaler.fit_transform(train_ds['YIELD'].values.reshape(-1, 1))\n",
    "valid_ds['YIELD'] = scaler.transform(valid_ds['YIELD'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6658d6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    136411.000000\n",
       "mean          0.597094\n",
       "std           0.255214\n",
       "min           0.000000\n",
       "25%           0.431193\n",
       "50%           0.642202\n",
       "75%           0.788991\n",
       "max          20.733945\n",
       "Name: YIELD, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds['YIELD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c38b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REACTANT:CC(O)CCc1ccccc1.O=S(=O)(F)c1ccc(Cl)cc1PRODUCT:CC(F)CCc1ccccc1CATALYST: \n"
     ]
    }
   ],
   "source": [
    "for i in df['input'].values:\n",
    "    if ' ' in i:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58cc8e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATALYST</th>\n",
       "      <th>REACTANT</th>\n",
       "      <th>REAGENT</th>\n",
       "      <th>SOLVENT</th>\n",
       "      <th>INTERNAL_STANDARD</th>\n",
       "      <th>NoData</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>YIELD</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2189652</th>\n",
       "      <td>CC(C1=C(P(C2CCCCC2)C2CCCCC2)C=C[CH]1)P(C(C)(C)...</td>\n",
       "      <td>C1CCNCC1.O=C(O)Cn1nnc(-c2cc(N3CCC(Oc4cc(F)ccc4...</td>\n",
       "      <td>CC(C)(C)[O-].[Na+]</td>\n",
       "      <td>COCCOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>REACTANT:C1CCNCC1.O=C(O)Cn1nnc(-c2cc(N3CCC(Oc4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189876</th>\n",
       "      <td>CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...</td>\n",
       "      <td>CC1(C)OB(c2ccc(N3CCN(S(=O)(=O)c4ccc(Cl)cc4)CC3...</td>\n",
       "      <td>O=P([O-])([O-])[O-].[K+]</td>\n",
       "      <td>C1CCOC1.O</td>\n",
       "      <td>CC(C)(C)c1ccc(-c2ccc(C(C)(C)C)cc2)cc1</td>\n",
       "      <td>None</td>\n",
       "      <td>COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>REACTANT:CC1(C)OB(c2ccc(N3CCN(S(=O)(=O)c4ccc(C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189877</th>\n",
       "      <td>CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...</td>\n",
       "      <td>CC1(C)OB(c2cccc(-c3nnn[nH]3)c2)OC1(C)C.Clc1ccc...</td>\n",
       "      <td>O=P([O-])([O-])[O-].[K+]</td>\n",
       "      <td>C1CCOC1.O</td>\n",
       "      <td>CC(C)(C)c1ccc(-c2ccc(C(C)(C)C)cc2)cc1</td>\n",
       "      <td>None</td>\n",
       "      <td>COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>REACTANT:CC1(C)OB(c2cccc(-c3nnn[nH]3)c2)OC1(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629755</th>\n",
       "      <td>COc1ccc(OC)c(P(C23CC4CC(CC(C4)C2)C3)(C23CC4CC(...</td>\n",
       "      <td>CCc1ccc(Cl)cc1.Cc1ccc(N)cc1</td>\n",
       "      <td>CN1CCCN2CCCN=C12.c1ccc2nocc2c1</td>\n",
       "      <td>CS(C)=O</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>REACTANT:CCc1ccc(Cl)cc1.Cc1ccc(N)cc1PRODUCT:Cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139006</th>\n",
       "      <td>None</td>\n",
       "      <td>CCCN(C(C)C)[C@H]1COc2cccc(C=O)c2C1.CN.O=C([O-]...</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>C1=CCCC=C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>REACTANT:CCCN(C(C)C)[C@H]1COc2cccc(C=O)c2C1.CN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28686</th>\n",
       "      <td>None</td>\n",
       "      <td>COC(=O)c1ncn(Cc2cc(C(F)(F)F)cc(C(F)(F)F)c2)c1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>CCO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CC(C)CN=C1C(c2ccccc2)=C(c2ccccc2)C(c2ccccc2)=C...</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>REACTANT:COC(=O)c1ncn(Cc2cc(C(F)(F)F)cc(C(F)(F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148098</th>\n",
       "      <td>None</td>\n",
       "      <td>CCN(CC)CC.COc1ccc2c(c1)CCN(c1nc(Cl)nc(C)c1C)C2...</td>\n",
       "      <td>None</td>\n",
       "      <td>CN(C)C=O</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CC(C)(C)[C@H](N)C(=O)O.CN(C)CC(=O)O.NCC(=O)O.N...</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>None</td>\n",
       "      <td>REACTANT:CCN(CC)CC.COc1ccc2c(c1)CCN(c1nc(Cl)nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178920</th>\n",
       "      <td>None</td>\n",
       "      <td>CCN(CC)CC.CN(C)C(On1nnc2cccnc21)=[N+](C)C.F[P-...</td>\n",
       "      <td>None</td>\n",
       "      <td>CN(C)C=O</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>COc1nc(N2CCCC2)ccc1[N+](=O)[O-]</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>None</td>\n",
       "      <td>REACTANT:CCN(CC)CC.CN(C)C(On1nnc2cccnc21)=[N+]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818600</th>\n",
       "      <td>CC[C@@H]1CN2CC[C@@H]1C[C@@H]2[C@H](Oc1nnc(O[C@...</td>\n",
       "      <td>CCOC(C)=O.COC(=O)/C=C/c1ccccc1Cl.CS(N)(=O)=O.O...</td>\n",
       "      <td>None</td>\n",
       "      <td>CC(C)(C)O.O</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cn1nnnc1-c1cc(Br)cc([N+](=O)[O-])c1</td>\n",
       "      <td>7090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>REACTANT:CCOC(C)=O.COC(=O)/C=C/c1ccccc1Cl.CS(N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606728</th>\n",
       "      <td>[Pd]</td>\n",
       "      <td>O=[N+]([O-])c1cnn(-c2ccccc2)c1</td>\n",
       "      <td>None</td>\n",
       "      <td>CCOC(C)=O.CO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CCCCCCCC/C=C\\CCCCCCCC(=O)O</td>\n",
       "      <td>69365.0</td>\n",
       "      <td>None</td>\n",
       "      <td>REACTANT:O=[N+]([O-])c1cnn(-c2ccccc2)c1PRODUCT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682053 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  CATALYST  \\\n",
       "2189652  CC(C1=C(P(C2CCCCC2)C2CCCCC2)C=C[CH]1)P(C(C)(C)...   \n",
       "2189876  CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...   \n",
       "2189877  CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...   \n",
       "1629755  COc1ccc(OC)c(P(C23CC4CC(CC(C4)C2)C3)(C23CC4CC(...   \n",
       "1139006                                               None   \n",
       "...                                                    ...   \n",
       "28686                                                 None   \n",
       "2148098                                               None   \n",
       "1178920                                               None   \n",
       "1818600  CC[C@@H]1CN2CC[C@@H]1C[C@@H]2[C@H](Oc1nnc(O[C@...   \n",
       "1606728                                               [Pd]   \n",
       "\n",
       "                                                  REACTANT  \\\n",
       "2189652  C1CCNCC1.O=C(O)Cn1nnc(-c2cc(N3CCC(Oc4cc(F)ccc4...   \n",
       "2189876  CC1(C)OB(c2ccc(N3CCN(S(=O)(=O)c4ccc(Cl)cc4)CC3...   \n",
       "2189877  CC1(C)OB(c2cccc(-c3nnn[nH]3)c2)OC1(C)C.Clc1ccc...   \n",
       "1629755                        CCc1ccc(Cl)cc1.Cc1ccc(N)cc1   \n",
       "1139006  CCCN(C(C)C)[C@H]1COc2cccc(C=O)c2C1.CN.O=C([O-]...   \n",
       "...                                                    ...   \n",
       "28686    COC(=O)c1ncn(Cc2cc(C(F)(F)F)cc(C(F)(F)F)c2)c1-...   \n",
       "2148098  CCN(CC)CC.COc1ccc2c(c1)CCN(c1nc(Cl)nc(C)c1C)C2...   \n",
       "1178920  CCN(CC)CC.CN(C)C(On1nnc2cccnc21)=[N+](C)C.F[P-...   \n",
       "1818600  CCOC(C)=O.COC(=O)/C=C/c1ccccc1Cl.CS(N)(=O)=O.O...   \n",
       "1606728                     O=[N+]([O-])c1cnn(-c2ccccc2)c1   \n",
       "\n",
       "                                REAGENT       SOLVENT  \\\n",
       "2189652              CC(C)(C)[O-].[Na+]        COCCOC   \n",
       "2189876        O=P([O-])([O-])[O-].[K+]     C1CCOC1.O   \n",
       "2189877        O=P([O-])([O-])[O-].[K+]     C1CCOC1.O   \n",
       "1629755  CN1CCCN2CCCN=C12.c1ccc2nocc2c1       CS(C)=O   \n",
       "1139006                            None            CO   \n",
       "...                                 ...           ...   \n",
       "28686                              None           CCO   \n",
       "2148098                            None      CN(C)C=O   \n",
       "1178920                            None      CN(C)C=O   \n",
       "1818600                            None   CC(C)(C)O.O   \n",
       "1606728                            None  CCOC(C)=O.CO   \n",
       "\n",
       "                             INTERNAL_STANDARD NoData  \\\n",
       "2189652                                   None   None   \n",
       "2189876  CC(C)(C)c1ccc(-c2ccc(C(C)(C)C)cc2)cc1   None   \n",
       "2189877  CC(C)(C)c1ccc(-c2ccc(C(C)(C)C)cc2)cc1   None   \n",
       "1629755                                   None   None   \n",
       "1139006                                   None   None   \n",
       "...                                        ...    ...   \n",
       "28686                                     None   None   \n",
       "2148098                                   None   None   \n",
       "1178920                                   None   None   \n",
       "1818600                                   None   None   \n",
       "1606728                                   None   None   \n",
       "\n",
       "                                                   PRODUCT    YIELD   TEMP  \\\n",
       "2189652   COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23      0.0   80.0   \n",
       "2189876   COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23      0.0  100.0   \n",
       "2189877   COC(=O)CC1CCc2cc(N3CCCCC3)cc3[nH]c(=O)c(=O)n1c23      0.0  100.0   \n",
       "1629755                     Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1      0.0   60.0   \n",
       "1139006                                         C1=CCCC=C1      0.0   None   \n",
       "...                                                    ...      ...    ...   \n",
       "28686    CC(C)CN=C1C(c2ccccc2)=C(c2ccccc2)C(c2ccccc2)=C...   1100.0   70.0   \n",
       "2148098  CC(C)(C)[C@H](N)C(=O)O.CN(C)CC(=O)O.NCC(=O)O.N...   2260.0   None   \n",
       "1178920                    COc1nc(N2CCCC2)ccc1[N+](=O)[O-]   3070.0   None   \n",
       "1818600                Cn1nnnc1-c1cc(Br)cc([N+](=O)[O-])c1   7090.0    0.0   \n",
       "1606728                         CCCCCCCC/C=C\\CCCCCCCC(=O)O  69365.0   None   \n",
       "\n",
       "                                                     input  \n",
       "2189652  REACTANT:C1CCNCC1.O=C(O)Cn1nnc(-c2cc(N3CCC(Oc4...  \n",
       "2189876  REACTANT:CC1(C)OB(c2ccc(N3CCN(S(=O)(=O)c4ccc(C...  \n",
       "2189877  REACTANT:CC1(C)OB(c2cccc(-c3nnn[nH]3)c2)OC1(C)...  \n",
       "1629755  REACTANT:CCc1ccc(Cl)cc1.Cc1ccc(N)cc1PRODUCT:Cc...  \n",
       "1139006  REACTANT:CCCN(C(C)C)[C@H]1COc2cccc(C=O)c2C1.CN...  \n",
       "...                                                    ...  \n",
       "28686    REACTANT:COC(=O)c1ncn(Cc2cc(C(F)(F)F)cc(C(F)(F...  \n",
       "2148098  REACTANT:CCN(CC)CC.COc1ccc2c(c1)CCN(c1nc(Cl)nc...  \n",
       "1178920  REACTANT:CCN(CC)CC.CN(C)C(On1nnc2cccnc21)=[N+]...  \n",
       "1818600  REACTANT:CCOC(C)=O.COC(=O)/C=C/c1ccccc1Cl.CS(N...  \n",
       "1606728  REACTANT:O=[N+]([O-])c1cnn(-c2ccccc2)c1PRODUCT...  \n",
       "\n",
       "[682053 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('YIELD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1008fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    682053.000000\n",
       "mean         64.337097\n",
       "std          88.808571\n",
       "min           0.000000\n",
       "25%          45.000000\n",
       "50%          69.000000\n",
       "75%          86.000000\n",
       "max       69365.000000\n",
       "Name: YIELD, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YIELD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429dd46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YIELD'].quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae85706a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, T5EncoderModel\n",
    "# model = T5EncoderModel.from_pretrained(CFG.pretrained_model_name_or_path)\n",
    "# model\n",
    "# # model2 = AutoModel.from_pretrained(CFG.pretrained_model_name_or_path, num_labels=1)\n",
    "# # model2 = model2.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a84a958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig\n",
    "# config = AutoConfig.from_pretrained('sagawa/ZINC-t5')\n",
    "# a = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels = 1)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63d4e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sagawa/ZINC-t5 were not used when initializing T5EncoderModel: ['decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'lm_head.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.final_layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.layer_norm.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/36372] Elapsed 0m 0s (remain 532m 45s) Loss: 3682.0491(3682.0491) Grad: 394.8093  LR: 0.00199998  \n",
      "Epoch: [1][100/36372] Elapsed 0m 30s (remain 180m 57s) Loss: 719.8199(1489.4144) Grad: 184.8497  LR: 0.00199815  \n",
      "Epoch: [1][200/36372] Elapsed 1m 2s (remain 187m 16s) Loss: 317.4121(1148.1907) Grad: 213.2992  LR: 0.00199632  \n",
      "Epoch: [1][300/36372] Elapsed 1m 36s (remain 193m 7s) Loss: 765.6782(1004.8354) Grad: 501.0276  LR: 0.00199448  \n",
      "Epoch: [1][400/36372] Elapsed 2m 11s (remain 197m 14s) Loss: 636.9699(916.7192) Grad: 228.2921  LR: 0.00199265  \n",
      "Epoch: [1][500/36372] Elapsed 2m 47s (remain 199m 42s) Loss: 807.5559(871.0504) Grad: 675.2719  LR: 0.00199082  \n",
      "Epoch: [1][600/36372] Elapsed 3m 23s (remain 201m 34s) Loss: 745.6779(842.3986) Grad: 243.9361  LR: 0.00198898  \n",
      "Epoch: [1][700/36372] Elapsed 3m 59s (remain 202m 52s) Loss: 790.9963(820.4609) Grad: 436.6902  LR: 0.00198715  \n",
      "Epoch: [1][800/36372] Elapsed 4m 34s (remain 203m 27s) Loss: 573.8173(810.0087) Grad: 276.0745  LR: 0.00198532  \n",
      "Epoch: [1][900/36372] Elapsed 5m 10s (remain 203m 41s) Loss: 871.4097(795.5218) Grad: 312.9189  LR: 0.00198349  \n",
      "Epoch: [1][1000/36372] Elapsed 5m 46s (remain 203m 56s) Loss: 883.5556(786.2708) Grad: 196.7359  LR: 0.00198165  \n",
      "Epoch: [1][1100/36372] Elapsed 6m 22s (remain 203m 59s) Loss: 407.8130(779.0840) Grad: 140.5117  LR: 0.00197982  \n",
      "Epoch: [1][1200/36372] Elapsed 6m 57s (remain 203m 50s) Loss: 735.6055(784.0800) Grad: 200.8688  LR: 0.00197799  \n",
      "Epoch: [1][1300/36372] Elapsed 7m 32s (remain 203m 27s) Loss: 518.1267(776.9184) Grad: 537.0828  LR: 0.00197615  \n",
      "Epoch: [1][1400/36372] Elapsed 8m 8s (remain 203m 8s) Loss: 867.0587(772.9595) Grad: 218.8938  LR: 0.00197432  \n",
      "Epoch: [1][1500/36372] Elapsed 8m 43s (remain 202m 46s) Loss: 1183.2753(772.4099) Grad: 608.8841  LR: 0.00197249  \n",
      "Epoch: [1][1600/36372] Elapsed 9m 19s (remain 202m 22s) Loss: 725.0300(769.7019) Grad: 198.6033  LR: 0.00197066  \n",
      "Epoch: [1][1700/36372] Elapsed 9m 54s (remain 201m 50s) Loss: 455.5828(765.9839) Grad: 253.9800  LR: 0.00196882  \n",
      "Epoch: [1][1800/36372] Elapsed 10m 29s (remain 201m 25s) Loss: 581.1550(765.0907) Grad: 352.0444  LR: 0.00196699  \n",
      "Epoch: [1][1900/36372] Elapsed 11m 4s (remain 200m 53s) Loss: 1107.7429(760.8787) Grad: 232.2362  LR: 0.00196516  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 248>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_ds, valid_ds)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(CFG\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    228\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 230\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# prediction削除\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     avg_val_loss \u001b[38;5;241m=\u001b[39m valid_fn(valid_loader, model, criterion, device)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m    129\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m/\u001b[39mCFG\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m    130\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), batch_size)\n\u001b[0;32m--> 131\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), CFG\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m CFG\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModel, T5EncoderModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "import math\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': tokenizer.additional_special_tokens + ['CATALYST:', 'REACTANT:', 'REAGENT:', 'SOLVENT:', 'INTERNAL_STANDARD:', 'NoData:','PRODUCT:', 'None']})\n",
    "CFG.tokenizer = tokenizer\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text, add_special_tokens=True, max_length=CFG.max_len, padding='max_length', return_offsets_mapping=False, truncation=True)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.inputs = df['input'].values\n",
    "        self.labels = df['YIELD'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.inputs[item])\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        \n",
    "        return inputs, label\n",
    "    \n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            if 't5' in cfg.model:\n",
    "                self.model = T5EncoderModel.from_pretrained(CFG.model)\n",
    "            else:\n",
    "                self.model = AutoModel.from_pretrained(CFG.model)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.model.resize_token_embeddings(len(cfg.tokenizer))\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "#         print(last_hidden_states.shape)\n",
    "        output = self.fc(self.fc_dropout(last_hidden_states)[:, 0, :].view(-1, self.config.hidden_size))\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val*n\n",
    "        self.count += n\n",
    "        self.avg = self.sum/self.count\n",
    "        \n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s/(percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "#         print(y_preds.shape)\n",
    "#         print(labels)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss/CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "            \n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss/CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    return losses.avg\n",
    "    \n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def train_loop(train_ds, valid_ds):\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_ds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_ds)\n",
    "    valid_labels = valid_ds['YIELD'].values\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    model = RegressionModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)], 'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)], 'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if 'model' not in n], 'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    \n",
    "    optimizer_parameters = get_optimizer_params(model, encoder_lr=CFG.lr, decoder_lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    num_train_steps = int(len(train_ds)/CFG.batch_size*CFG.epochs)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps)\n",
    "    \n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    best_loss = 0\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "        \n",
    "        # prediction削除\n",
    "        avg_val_loss = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "    \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Lowest Loss: {best_loss:.4f} Model')\n",
    "            torch.save(model.state_dict(), OUTPUT_DIR+f\"{CFG.model}_best.pth\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    train_loop(train_ds, valid_ds)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ca374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9112e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3be574e6e217f2e3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sagawa/.cache/huggingface/datasets/csv/default-3be574e6e217f2e3/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n",
      "Dataset csv downloaded and prepared to /home/sagawa/.cache/huggingface/datasets/csv/default-3be574e6e217f2e3/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'PRODUCT'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input', 'PRODUCT'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../all_ord_reaction_uniq_with_attr_v3.tsv')\n",
    "\n",
    "df = df[~df['PRODUCT'].isna()]\n",
    "for col in ['CATALYST', 'REACTANT', 'REAGENT', 'SOLVENT', 'INTERNAL_STANDARD', 'NoData','PRODUCT', 'YIELD', 'TEMP']:\n",
    "    df[col] = df[col].fillna('None')\n",
    "df['input'] = 'REACTANT:' + df['REACTANT']  + 'CATALYST:' + df['CATALYST'] + 'REAGENT:' + df['REAGENT'] + 'SOLVENT:' + df['SOLVENT'] + 'NoData:' + df['NoData']\n",
    "# df['input'] = 'REACTANT:' + df['REACTANT'] + 'PRODUCT:' + df['PRODUCT'] + 'CATALYST:' + df['CATALYST']\n",
    "train_ds = df[:int(len(df)*0.8)]\n",
    "valid_ds = df[int(len(df)*0.8):]\n",
    "\n",
    "train_ds[['input', 'PRODUCT']].to_csv('../../ord-train-debug.csv', index=False)\n",
    "valid_ds[['input', 'PRODUCT']].to_csv('../../ord-test-debug.csv', index=False)\n",
    "data_files = {'train': '../../ord-train-debug.csv', 'validation': '../../ord-test-debug.csv'}\n",
    "dataset = load_dataset('csv', data_files=data_files)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples['input'] + examples['product']\n",
    "    model_inputs = tokenizer(inputs, max_length=CFG.max_len, truncation=True)\n",
    "    model_inputs['labels'] = float(examples['yield'])\n",
    "    return model_inputs\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    \n",
    "    return {'mse':mse}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric('sacrebleu')\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)# np.where(条件式, x, y) True=>xi, False=>yiを要素と持つリストを返す\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {'bleu': result['score']}\n",
    "\n",
    "\n",
    "#load tokenizer\n",
    "try: # load pretrained tokenizer from local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(os.path.abspath(CFG.pretrained_model_name_or_path), return_tensors='pt')\n",
    "except: # load pretrained tokenizer from huggingface model hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.pretrained_model_name_or_path, return_tensors='pt')\n",
    "    \n",
    "if CFG.multitask:\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens':tokenizer.additional_special_tokens + ['Product:', 'Reactants:']})\n",
    "else:\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens':tokenizer.additional_special_tokens + ['Reactants:']})\n",
    "tokenizer.add_tokens('.')\n",
    "\n",
    "#load model\n",
    "if CFG.model == 't5':\n",
    "    try: # load pretrained model from local directory\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(os.path.abspath(CFG.pretrained_model_name_or_path), from_flax=True)\n",
    "    except: # load pretrained model from huggingface model hub\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(CFG.pretrained_model_name_or_path, from_flax=True)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "elif CFG.model == 'deberta':\n",
    "    try: # load pretrained model from local directory\n",
    "        model = EncoderDecoderModel.from_encoder_decoder_pretrained(os.path.abspath(CFG.pretrained_model_name_or_path), 'roberta-large')\n",
    "    except: # load pretrained model from huggingface model hub\n",
    "        model = EncoderDecoderModel.from_encoder_decoder_pretrained(os.path.abspath(CFG.pretrained_model_name_or_path), 'roberta-large')\n",
    "    model.encoder.resize_token_embeddings(len(tokenizer))\n",
    "    model.decoder.resize_token_embeddings(len(tokenizer))\n",
    "    config_encoder = model.config.encoder\n",
    "    config_decoder = model.config.decoder\n",
    "    config_decoder.is_decoder = True\n",
    "    config_decoder.add_cross_attention = True\n",
    "    model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    CFG.model,\n",
    "    evaluation_strategy=CFG.evaluation_strategy,\n",
    "    save_strategy=CFG.save_strategy,\n",
    "    learning_rate=CFG.lr,\n",
    "    per_device_train_batch_size=CFG.batch_size,\n",
    "    per_device_eval_batch_size=CFG.batch_size,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    save_total_limit=CFG.save_total_limit,\n",
    "    num_train_epochs=CFG.epochs,\n",
    "    predict_with_generate=True,\n",
    "    fp16=CFG.fp16,\n",
    "    disable_tqdm=CFG.disable_tqdm,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bcf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be27454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16df29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a1a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1cf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c421a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c413c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['product', 'reactant'],\n",
       "        num_rows: 855625\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['product', 'reactant'],\n",
       "        num_rows: 106952\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['product', 'reactant'],\n",
       "        num_rows: 106952\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b61e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b2d5b87c6450700e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sagawa/.cache/huggingface/datasets/csv/default-b2d5b87c6450700e/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004d17848bcf4dd9a480ec5c19086c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7206bb187724f06bee3cf3a6d4d1704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sagawa/.cache/huggingface/datasets/csv/default-b2d5b87c6450700e/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868bbb0fd6d444948af2ecfbe8acfa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m data_files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-valid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      6\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39mdata_files)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../tcrp-test/transformer-chemical-reaction-prediciton/data/ord_datasets.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv('../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-train.csv')\n",
    "# validation = pd.read_csv('../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-valid.csv')\n",
    "# test = pd.read_csv('../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-test.csv')\n",
    "from datasets import load_dataset\n",
    "data_files = {\"train\": \"../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-train.csv\", \"test\": \"../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-test.csv\", \"validation\":\"../tcrp-test/transformer-chemical-reaction-prediciton/data/all_ord_reaction_uniq_canonicalized-valid.csv\"}\n",
    "ds = load_dataset('csv', data_files=data_files)\n",
    "ds.to_json(\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ord_datasets.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06800fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/sagawa/.huggingface/token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2612b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagawa/anaconda3/lib/python3.9/site-packages/huggingface_hub/hf_api.py:79: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.8. Pass `repo_id` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/sagawa/ord-uniq-canonicalized'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "repo_url = create_repo(name=\"ord-uniq-canonicalized\", repo_type=\"dataset\")\n",
    "repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8794699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aaeb3a68364d6e924ba35e5087c084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53152a1f1a174b53bb36c02f66e940f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d894a9189e45dd942d45fa728b8b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(repo_id=\"ord-uniq-canonicalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01988236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0ccd2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ae5678ec841ec48f\n",
      "Reusing dataset csv (/home/sagawa/.cache/huggingface/datasets/csv/default-ae5678ec841ec48f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dd4ab28b73416b956bb9929490c0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 8999964\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 999996\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"../tcrp-test/transformer-chemical-reaction-prediciton/data/pubchem-10m-canonicalized-train.csv\", \"validation\":\"../tcrp-test/transformer-chemical-reaction-prediciton/data/pubchem-10m-canonicalized-valid.csv\"}\n",
    "ds = load_dataset('csv', data_files=data_files)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05de5a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagawa/anaconda3/lib/python3.9/site-packages/huggingface_hub/hf_api.py:79: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.8. Pass `repo_id` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/sagawa/pubchem-10m-canonicalized'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_url = create_repo(name=\"pubchem-10m-canonicalized\", repo_type=\"dataset\")\n",
    "repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3fa575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53a26ca30114303bde8bd458ccc6890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4925e29c47849128d37960ab5b6a8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(repo_id=\"pubchem-10m-canonicalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e1e179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [10942073,\n",
       "  3929867,\n",
       "  1828479,\n",
       "  4329395,\n",
       "  14351797,\n",
       "  6552409,\n",
       "  20973385,\n",
       "  22448411,\n",
       "  22636960,\n",
       "  2282403],\n",
       " 'text': ['O=C1NCCN1[C@@H]1CCC[NH+](Cc2cccc(O)c2)C1',\n",
       "  'CC(=O)N1c2ccc(S(=O)(=O)N3CCCC3)cc2C[C@@H]1C(=O)NCCN1CCCCCC1',\n",
       "  'Cc1nc(-c2ccc(NC(=O)[C@H]3C[C@H]4CC[C@@H]3O4)cc2)cs1',\n",
       "  'COc1ccc(C(=O)[C@H](C)Sc2nc(-c3cccs3)n[n-]2)cc1OC',\n",
       "  'CCOC(=O)c1sc(NC(=O)CCCS(=O)(=O)c2ccc(F)cc2)nc1-c1ccccc1',\n",
       "  'O=C(NC[C@H]1CCCO1)c1ccc2c(c1)ncn2-c1ccccc1',\n",
       "  'O=C(c1cc(F)c(F)cc1F)N1CC[NH+]([C@H](c2ccccc2)c2ccc(F)cc2)CC1',\n",
       "  'Cc1c(C(=O)N(Cc2ccccc2)[C@@H](C)CCO)cnn1-c1ccccn1',\n",
       "  'C[C@@H](Oc1cccc(C#N)c1)C(=O)Nc1cc(C2CCOCC2)n[nH]1',\n",
       "  'CCCCn1c(S[C@@H](C)C(=O)Nc2ccc(C(C)=O)cc2)n[nH]c1=O']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f385d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-train.csv\")\n",
    "train = train.rename(columns={'text':'smiles'}).drop(['Unnamed: 0'], axis=1)\n",
    "train.to_csv(\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-train.csv\", index=False)\n",
    "valid = pd.read_csv(\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-valid.csv\")\n",
    "valid = valid.rename(columns={'text':'smiles'}).drop(['Unnamed: 0'], axis=1)\n",
    "valid.to_csv(\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-valid.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26a0a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-681997cf8c885a68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sagawa/.cache/huggingface/datasets/csv/default-681997cf8c885a68/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec5e1d537174321b1661e89e4cc9e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd10a4191af499eba5339f96fb71281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sagawa/.cache/huggingface/datasets/csv/default-681997cf8c885a68/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bc8de11ff240d1b5986946ce5cb8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 20693269\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 2299253\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-train.csv\", \"validation\":\"../tcrp-test/transformer-chemical-reaction-prediciton/data/ZINC-canonicalized-valid.csv\"}\n",
    "ds = load_dataset('csv', data_files=data_files)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5548b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagawa/anaconda3/lib/python3.9/site-packages/huggingface_hub/hf_api.py:79: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.8. Pass `repo_id` instead.\n",
      "  warnings.warn(\n",
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967e9d4485b54c79918e2d5b083091a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8964024857ca427db22363a3fad449d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repo_url = create_repo(name=\"ZINC-canonicalized\", repo_type=\"dataset\")\n",
    "ds.push_to_hub(repo_id=\"ZINC-canonicalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25aad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b01d465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6daf966d6744dcbbe39a22a15ec25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration sagawa--pubchem-10m-canonicalized-93982af44e6a1c55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: 250.77 MiB, generated: 463.22 MiB, post-processed: Unknown size, total: 713.99 MiB) to /home/sagawa/.cache/huggingface/datasets/sagawa___parquet/sagawa--pubchem-10m-canonicalized-93982af44e6a1c55/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cf5b91ecf1407aacb468c6c22e42f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0b9f6eefe84e79ba6db73bd90934bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127f0b0e35d74ed2840f864ec5fb3e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/237M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c1dab0938944f5b375ed72a58e9dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/sagawa/.cache/huggingface/datasets/sagawa___parquet/sagawa--pubchem-10m-canonicalized-93982af44e6a1c55/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00781e1315094355ad59907f2cada5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 999996\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['smiles'],\n",
       "        num_rows: 8999964\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('sagawa/pubchem-10m-canonicalized')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13044132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
